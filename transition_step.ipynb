{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"transition_step.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"z2C-ZtSwEmCW","colab_type":"text"},"source":["<h2>Mount Drive</h2>"]},{"cell_type":"code","metadata":{"id":"nxexa9SPw1XV","colab_type":"code","outputId":"581af568-5ec6-4acc-8a5c-6a49d50e5ce5","executionInfo":{"status":"ok","timestamp":1590396937229,"user_tz":240,"elapsed":24764,"user":{"displayName":"Alejandro Martinez","photoUrl":"","userId":"09355511104721895281"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4J4SP_OMEeiv","colab_type":"text"},"source":["<h2>Navigate to mid slices and set up tuned models directory</h2>"]},{"cell_type":"code","metadata":{"id":"gApKSCBzDn29","colab_type":"code","outputId":"1aa6a970-ba93-4d27-e4fe-7aeab32ef1ee","executionInfo":{"status":"error","timestamp":1590830296029,"user_tz":240,"elapsed":1649,"user":{"displayName":"Alejandro Martinez","photoUrl":"","userId":"09355511104721895281"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["import os\n","import pandas as pd\n","from time import sleep\n","\n","os.chdir('drive/My Drive/mid_slices')\n","cwd = os.getcwd()\n","\n","#create models directory if it doesn't already exist\n","model_dir = 'tuned_models'\n","models_path = os.path.join(cwd,model_dir)\n","try:\n","    os.mkdir(models_path)\n","except:\n","    print(\"WARNING: tuned models directory already exists\")\n","\n","#load transition metadata as datframe\n","df = pd.read_csv(os.path.join(cwd,'mid_slice_metadata.csv'))\n","\n","#display unique labels\n","print(df['Label'].unique())\n","print(df['Soft Labels'].unique())"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a14e82f85a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/mid_slices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/mid_slices'"]}]},{"cell_type":"markdown","metadata":{"id":"8xAAiQHXpK9n","colab_type":"text"},"source":["<h2>Get Transition slice chunk paths</h2>"]},{"cell_type":"code","metadata":{"id":"XjcdfjYLoG6f","colab_type":"code","outputId":"ae4249b7-f9eb-4a93-8ccf-211bd4e41724","executionInfo":{"status":"ok","timestamp":1590396955058,"user_tz":240,"elapsed":3001,"user":{"displayName":"Alejandro Martinez","photoUrl":"","userId":"09355511104721895281"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["import os\n","import numpy as np\n","\n","#method to extract slice number\n","def get_slices_num(slice):\n","  num = int(slice[5:-4])\n","  return(num)\n","\n","os.chdir('drive/My Drive/mid_slices')\n","print(os.getcwd())\n","\n","#get slice chunk filepaths\n","np_slices = {}\n","for (dir,root,files) in os.walk(os.getcwd()):\n","  for file in files:\n","    if '.npy' in file:\n","      num = get_slices_num(file)\n","      np_slices[num] = file\n","\n","#sort slices\n","sorted_slices = sorted(np_slices.keys())\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/mid_slices\n","{6: 'chunk6.npy', 7: 'chunk7.npy', 10: 'chunk10.npy', 8: 'chunk8.npy', 9: 'chunk9.npy', 5: 'chunk5.npy', 11: 'chunk11.npy', 12: 'chunk12.npy', 13: 'chunk13.npy', 14: 'chunk14.npy', 15: 'chunk15.npy', 16: 'chunk16.npy', 17: 'chunk17.npy', 18: 'chunk18.npy', 19: 'chunk19.npy', 20: 'chunk20.npy', 21: 'chunk21.npy', 22: 'chunk22.npy', 23: 'chunk23.npy', 24: 'chunk24.npy', 25: 'chunk25.npy', 26: 'chunk26.npy', 27: 'chunk27.npy', 28: 'chunk28.npy', 29: 'chunk29.npy', 30: 'chunk30.npy', 31: 'chunk31.npy', 32: 'chunk32.npy', 33: 'chunk33.npy', 34: 'chunk34.npy', 35: 'chunk35.npy', 36: 'chunk36.npy', 37: 'chunk37.npy', 38: 'chunk38.npy', 39: 'chunk39.npy', 40: 'chunk40.npy', 41: 'chunk41.npy', 42: 'chunk42.npy', 43: 'chunk43.npy', 44: 'chunk44.npy', 45: 'chunk45.npy', 46: 'chunk46.npy', 47: 'chunk47.npy', 48: 'chunk48.npy', 49: 'chunk49.npy', 50: 'chunk50.npy', 51: 'chunk51.npy', 52: 'chunk52.npy', 53: 'chunk53.npy', 54: 'chunk54.npy', 55: 'chunk55.npy', 56: 'chunk56.npy', 57: 'chunk57.npy', 58: 'chunk58.npy', 59: 'chunk59.npy', 60: 'chunk60.npy', 61: 'chunk61.npy', 62: 'chunk62.npy', 63: 'chunk63.npy', 64: 'chunk64.npy', 65: 'chunk65.npy', 66: 'chunk66.npy', 67: 'chunk67.npy', 68: 'chunk68.npy', 69: 'chunk69.npy', 70: 'chunk70.npy', 71: 'chunk71.npy', 72: 'chunk72.npy', 73: 'chunk73.npy', 74: 'chunk74.npy', 75: 'chunk75.npy', 76: 'chunk76.npy', 77: 'chunk77.npy', 78: 'chunk78.npy', 79: 'chunk79.npy', 80: 'chunk80.npy', 81: 'chunk81.npy', 82: 'chunk82.npy', 83: 'chunk83.npy', 84: 'chunk84.npy', 85: 'chunk85.npy', 86: 'chunk86.npy', 87: 'chunk87.npy', 88: 'chunk88.npy', 89: 'chunk89.npy', 90: 'chunk90.npy', 91: 'chunk91.npy', 92: 'chunk92.npy', 93: 'chunk93.npy', 94: 'chunk94.npy', 95: 'chunk95.npy', 96: 'chunk96.npy', 97: 'chunk97.npy', 98: 'chunk98.npy', 99: 'chunk99.npy', 100: 'chunk100.npy'}\n","length of np_slices: 96\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ab9uaxY70h9Q","colab_type":"text"},"source":["<h2>Load CT slice image arrays</h2>\n","\n"]},{"cell_type":"code","metadata":{"id":"GpzViI3KpJKN","colab_type":"code","outputId":"57ade140-e3cb-4f3d-9eec-0e3b76a961bf","executionInfo":{"status":"ok","timestamp":1590397747390,"user_tz":240,"elapsed":636798,"user":{"displayName":"Alejandro Martinez","photoUrl":"","userId":"09355511104721895281"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import time\n","import cv2\n","from numpy import save, asarray\n","from keras.preprocessing.image import array_to_img,save_img\n","import tensorflow as tf\n","from time import sleep\n","\n","#method to reshape image dimensions\n","def decode_img(img,IMG_WIDTH,IMG_HEIGHT):\n","  return(cv2.resize(img,(IMG_WIDTH,IMG_HEIGHT)))\n","\n","#start counter\n","start = time.perf_counter()\n","\n","#data array\n","data = []\n","\n","#load every slice per chunk\n","for chunk_ in  sorted_slices:\n","\n","  #load np slice chunk\n","  chunk = np.load(np_slices[chunk_])\n","  \n","  #format each slice to (224,224,3) if not already in the format\n","  for slice_ in chunk:\n","    slice_ = decode_img(scan,224,224)\n","\n","    if slice_.ndim < 3:\n","      slice_ = np.asarray([scan]*3)\n","      slice_ = slice_.reshape(224,224,3)\n","    \n","    #append slice to data array\n","    data.append(slice_)\n","  \n","#finish counter\n","finish = time.perf_counter()\n","print(f'this process took {finish-start} seconds')\n","\n","\n","\n","  \n","\n","\n","\n","\n","\n","  \n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/mid_slices\n","chunk5.npy with shape (106, 512, 512, 3) loaded at: 1300.619780654\n","data length: 0\n","\n","\n","chunk6.npy with shape (106, 512, 512, 3) loaded at: 1301.061699985\n","data length: 106\n","\n","\n","chunk7.npy with shape (106, 512, 512, 3) loaded at: 1301.461012015\n","data length: 212\n","\n","\n","chunk8.npy with shape (106, 512, 512, 3) loaded at: 1301.873569543\n","data length: 318\n","\n","\n","chunk9.npy with shape (106, 512, 512, 3) loaded at: 1302.311760171\n","data length: 424\n","\n","\n","chunk10.npy with shape (106, 512, 512, 3) loaded at: 1302.714486868\n","data length: 530\n","\n","\n","chunk11.npy with shape (106, 512, 512, 3) loaded at: 1303.14820651\n","data length: 636\n","\n","\n","chunk12.npy with shape (106, 512, 512, 3) loaded at: 1303.554250729\n","data length: 742\n","\n","\n","chunk13.npy with shape (106, 512, 512, 3) loaded at: 1303.970615222\n","data length: 848\n","\n","\n","chunk14.npy with shape (106, 512, 512, 3) loaded at: 1304.379421783\n","data length: 954\n","\n","\n","chunk15.npy with shape (106, 512, 512, 3) loaded at: 1304.783659072\n","data length: 1060\n","\n","\n","chunk16.npy with shape (106, 512, 512, 3) loaded at: 1305.194872033\n","data length: 1166\n","\n","\n","chunk17.npy with shape (106, 512, 512, 3) loaded at: 1305.64947524\n","data length: 1272\n","\n","\n","chunk18.npy with shape (106, 512, 512, 3) loaded at: 1306.072768001\n","data length: 1378\n","\n","\n","chunk19.npy with shape (106, 512, 512, 3) loaded at: 1306.487965659\n","data length: 1484\n","\n","\n","chunk20.npy with shape (106, 512, 512, 3) loaded at: 1306.886983228\n","data length: 1590\n","\n","\n","chunk21.npy with shape (106, 512, 512, 3) loaded at: 1307.284014107\n","data length: 1696\n","\n","\n","chunk22.npy with shape (106, 512, 512, 3) loaded at: 1307.71270629\n","data length: 1802\n","\n","\n","chunk23.npy with shape (106, 512, 512, 3) loaded at: 1308.136321755\n","data length: 1908\n","\n","\n","chunk24.npy with shape (106, 512, 512, 3) loaded at: 1312.591637501\n","data length: 2014\n","\n","\n","chunk25.npy with shape (106, 512, 512, 3) loaded at: 1317.030960466\n","data length: 2120\n","\n","\n","chunk26.npy with shape (106, 512, 512, 3) loaded at: 1321.955337379\n","data length: 2226\n","\n","\n","chunk27.npy with shape (106, 512, 512, 3) loaded at: 1327.491335022\n","data length: 2332\n","\n","\n","chunk28.npy with shape (106, 512, 512, 3) loaded at: 1331.533736636\n","data length: 2438\n","\n","\n","chunk29.npy with shape (106, 512, 512, 3) loaded at: 1336.210402036\n","data length: 2544\n","\n","\n","chunk30.npy with shape (106, 512, 512, 3) loaded at: 1341.023213142\n","data length: 2650\n","\n","\n","chunk31.npy with shape (106, 512, 512, 3) loaded at: 1345.251287764\n","data length: 2756\n","\n","\n","chunk32.npy with shape (106, 512, 512, 3) loaded at: 1351.609905658\n","data length: 2862\n","\n","\n","chunk33.npy with shape (106, 512, 512, 3) loaded at: 1360.131592609\n","data length: 2968\n","\n","\n","chunk34.npy with shape (106, 512, 512, 3) loaded at: 1371.946403663\n","data length: 3074\n","\n","\n","chunk35.npy with shape (106, 512, 512, 3) loaded at: 1376.985093969\n","data length: 3180\n","\n","\n","chunk36.npy with shape (106, 512, 512, 3) loaded at: 1389.708411434\n","data length: 3286\n","\n","\n","chunk37.npy with shape (106, 512, 512, 3) loaded at: 1394.469213593\n","data length: 3392\n","\n","\n","chunk38.npy with shape (106, 512, 512, 3) loaded at: 1401.180098199\n","data length: 3498\n","\n","\n","chunk39.npy with shape (106, 512, 512, 3) loaded at: 1408.592830054\n","data length: 3604\n","\n","\n","chunk40.npy with shape (106, 512, 512, 3) loaded at: 1420.847304633\n","data length: 3710\n","\n","\n","chunk41.npy with shape (106, 512, 512, 3) loaded at: 1429.176687242\n","data length: 3816\n","\n","\n","chunk42.npy with shape (106, 512, 512, 3) loaded at: 1434.183670061\n","data length: 3922\n","\n","\n","chunk43.npy with shape (106, 512, 512, 3) loaded at: 1450.818690668\n","data length: 4028\n","\n","\n","chunk44.npy with shape (106, 512, 512, 3) loaded at: 1457.949642202\n","data length: 4134\n","\n","\n","chunk45.npy with shape (106, 512, 512, 3) loaded at: 1469.44424978\n","data length: 4240\n","\n","\n","chunk46.npy with shape (106, 512, 512, 3) loaded at: 1473.552312627\n","data length: 4346\n","\n","\n","chunk47.npy with shape (106, 512, 512, 3) loaded at: 1478.03115776\n","data length: 4452\n","\n","\n","chunk48.npy with shape (106, 512, 512, 3) loaded at: 1487.557782163\n","data length: 4558\n","\n","\n","chunk49.npy with shape (106, 512, 512, 3) loaded at: 1496.462153032\n","data length: 4664\n","\n","\n","chunk50.npy with shape (106, 512, 512, 3) loaded at: 1500.966009366\n","data length: 4770\n","\n","\n","chunk51.npy with shape (106, 512, 512, 3) loaded at: 1512.083237004\n","data length: 4876\n","\n","\n","chunk52.npy with shape (106, 512, 512, 3) loaded at: 1517.303734357\n","data length: 4982\n","\n","\n","chunk53.npy with shape (106, 512, 512, 3) loaded at: 1529.741731809\n","data length: 5088\n","\n","\n","chunk54.npy with shape (106, 512, 512, 3) loaded at: 1536.561453274\n","data length: 5194\n","\n","\n","chunk55.npy with shape (106, 512, 512, 3) loaded at: 1546.357271841\n","data length: 5300\n","\n","\n","chunk56.npy with shape (106, 512, 512, 3) loaded at: 1554.671353963\n","data length: 5406\n","\n","\n","chunk57.npy with shape (106, 512, 512, 3) loaded at: 1563.440080063\n","data length: 5512\n","\n","\n","chunk58.npy with shape (106, 512, 512, 3) loaded at: 1572.550218832\n","data length: 5618\n","\n","\n","chunk59.npy with shape (106, 512, 512, 3) loaded at: 1580.293241381\n","data length: 5724\n","\n","\n","chunk60.npy with shape (106, 512, 512, 3) loaded at: 1585.51345349\n","data length: 5830\n","\n","\n","chunk61.npy with shape (106, 512, 512, 3) loaded at: 1596.263490291\n","data length: 5936\n","\n","\n","chunk62.npy with shape (106, 512, 512, 3) loaded at: 1603.11187538\n","data length: 6042\n","\n","\n","chunk63.npy with shape (106, 512, 512, 3) loaded at: 1617.89110591\n","data length: 6148\n","\n","\n","chunk64.npy with shape (106, 512, 512, 3) loaded at: 1623.020886803\n","data length: 6254\n","\n","\n","chunk65.npy with shape (106, 512, 512, 3) loaded at: 1637.722448538\n","data length: 6360\n","\n","\n","chunk66.npy with shape (106, 512, 512, 3) loaded at: 1641.87578848\n","data length: 6466\n","\n","\n","chunk67.npy with shape (106, 512, 512, 3) loaded at: 1645.923319998\n","data length: 6572\n","\n","\n","chunk68.npy with shape (106, 512, 512, 3) loaded at: 1660.315779191\n","data length: 6678\n","\n","\n","chunk69.npy with shape (106, 512, 512, 3) loaded at: 1669.344014828\n","data length: 6784\n","\n","\n","chunk70.npy with shape (106, 512, 512, 3) loaded at: 1673.832269995\n","data length: 6890\n","\n","\n","chunk71.npy with shape (106, 512, 512, 3) loaded at: 1678.711682674\n","data length: 6996\n","\n","\n","chunk72.npy with shape (106, 512, 512, 3) loaded at: 1690.825687857\n","data length: 7102\n","\n","\n","chunk73.npy with shape (106, 512, 512, 3) loaded at: 1698.907811976\n","data length: 7208\n","\n","\n","chunk74.npy with shape (106, 512, 512, 3) loaded at: 1704.676007768\n","data length: 7314\n","\n","\n","chunk75.npy with shape (106, 512, 512, 3) loaded at: 1711.650384207\n","data length: 7420\n","\n","\n","chunk76.npy with shape (106, 512, 512, 3) loaded at: 1726.555660015\n","data length: 7526\n","\n","\n","chunk77.npy with shape (106, 512, 512, 3) loaded at: 1731.751160005\n","data length: 7632\n","\n","\n","chunk78.npy with shape (106, 512, 512, 3) loaded at: 1741.707708553\n","data length: 7738\n","\n","\n","chunk79.npy with shape (106, 512, 512, 3) loaded at: 1748.275021268\n","data length: 7844\n","\n","\n","chunk80.npy with shape (106, 512, 512, 3) loaded at: 1754.30025905\n","data length: 7950\n","\n","\n","chunk81.npy with shape (106, 512, 512, 3) loaded at: 1768.85319193\n","data length: 8056\n","\n","\n","chunk82.npy with shape (106, 512, 512, 3) loaded at: 1773.520545221\n","data length: 8162\n","\n","\n","chunk83.npy with shape (106, 512, 512, 3) loaded at: 1786.605634379\n","data length: 8268\n","\n","\n","chunk84.npy with shape (106, 512, 512, 3) loaded at: 1791.989275093\n","data length: 8374\n","\n","\n","chunk85.npy with shape (106, 512, 512, 3) loaded at: 1799.027466332\n","data length: 8480\n","\n","\n","chunk86.npy with shape (106, 512, 512, 3) loaded at: 1806.975927766\n","data length: 8586\n","\n","\n","chunk87.npy with shape (106, 512, 512, 3) loaded at: 1820.684095435\n","data length: 8692\n","\n","\n","chunk88.npy with shape (106, 512, 512, 3) loaded at: 1828.911867618\n","data length: 8798\n","\n","\n","chunk89.npy with shape (106, 512, 512, 3) loaded at: 1836.264029495\n","data length: 8904\n","\n","\n","chunk90.npy with shape (106, 512, 512, 3) loaded at: 1841.06024685\n","data length: 9010\n","\n","\n","chunk91.npy with shape (106, 512, 512, 3) loaded at: 1851.751127082\n","data length: 9116\n","\n","\n","chunk92.npy with shape (106, 512, 512, 3) loaded at: 1862.05736791\n","data length: 9222\n","\n","\n","chunk93.npy with shape (106, 512, 512, 3) loaded at: 1868.127675659\n","data length: 9328\n","\n","\n","chunk94.npy with shape (106, 512, 512, 3) loaded at: 1878.284040685\n","data length: 9434\n","\n","\n","chunk95.npy with shape (106, 512, 512, 3) loaded at: 1884.030756336\n","data length: 9540\n","\n","\n","chunk96.npy with shape (106, 512, 512, 3) loaded at: 1894.322102251\n","data length: 9646\n","\n","\n","chunk97.npy with shape (106, 512, 512, 3) loaded at: 1905.352272474\n","data length: 9752\n","\n","\n","chunk98.npy with shape (106, 512, 512, 3) loaded at: 1909.392311666\n","data length: 9858\n","\n","\n","chunk99.npy with shape (106, 512, 512, 3) loaded at: 1915.746640011\n","data length: 9964\n","\n","\n","chunk100.npy with shape (106, 512, 512, 3) loaded at: 1925.884199369\n","data length: 10070\n","\n","\n","this process took 635.5234995420001 seconds\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C4ismKX_9c3V","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Ny42A6Tjw1Xe","colab_type":"text"},"source":["<h2>Divide Transition dataset</h2>"]},{"cell_type":"code","metadata":{"id":"LUxVPuzsw1Xe","colab_type":"code","outputId":"59cf5f33-4f1b-4cf2-a2e4-f15dbfd41113","executionInfo":{"status":"ok","timestamp":1590397747392,"user_tz":240,"elapsed":636789,"user":{"displayName":"Alejandro Martinez","photoUrl":"","userId":"09355511104721895281"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","\n","#start counter\n","start = time.perf_counter()\n","\n","#exclude corrupted 424 slices \n","labels = df['Soft Labels']       \n","labels =labels[424:]\n","\n","#split 80:20 train test data\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.20)\n","\n","#finish counter\n","finish = time.perf_counter()\n","print(f'this process took {finish-start} seconds')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["424      7\n","425      0\n","426      0\n","427      0\n","428      0\n","        ..\n","10595    6\n","10596    5\n","10597    5\n","10598    5\n","10599    5\n","Name: Soft Labels, Length: 10176, dtype: int64\n","this process took 0.09296261600002254 seconds\n","10176\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xwloULNce6zS","colab_type":"text"},"source":["<h2>Convert Data to Numpy Arrays</h2>"]},{"cell_type":"code","metadata":{"id":"bJOkXRReed5K","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","#convert divided data into numpy arrays\n","X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x_5UFTfPgTZo","colab_type":"text"},"source":["<h2>Initialize Networks</h2>"]},{"cell_type":"code","metadata":{"id":"GAkjDDuIw1XQ","colab_type":"code","outputId":"d693fff9-c9af-410a-de4f-d4e5a4d3a347","executionInfo":{"status":"ok","timestamp":1590399025374,"user_tz":240,"elapsed":46131,"user":{"displayName":"Alejandro Martinez","photoUrl":"","userId":"09355511104721895281"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["from keras.applications import MobileNetV2, InceptionV3, ResNet50V2, VGG16, VGG19, Xception, ResNet101V2, DenseNet121, ResNet152V2, DenseNet169, DenseNet201 ##\n","from keras import datasets, layers, models\n","from keras.models import load_model\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as npf\n","from time import sleep\n","\n","#input dimensions\n","img_shape = (224,224,3)\n","\n","\n","#model initialization\n","densenet121 = DenseNet121(weights='imagenet', include_top=False, input_shape=img_shape)\n","densenet169 = DenseNet169(weights='imagenet', include_top=False, input_shape=img_shape)\n","resnet50 = ResNet50V2(weights='imagenet', include_top=False, input_shape=img_shape)\n","resnet101 = ResNet101V2(weights='imagenet', include_top=False, input_shape=img_shape)\n","\n","#create model list\n","model_list = [densenet121,densenet169,resnet50,resnet101]\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/mid_slices\n","Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94674944/94668760 [==============================] - 7s 0us/step\n","Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","171319296/171317808 [==============================] - 11s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W7k9PcyZw1XX","colab_type":"text"},"source":["<h2>Freeze layers</h2>"]},{"cell_type":"code","metadata":{"id":"M6m8NtUZw1XY","colab_type":"code","outputId":"893ab1b5-3712-4bb6-bab0-0ac677a80d1b","executionInfo":{"status":"error","timestamp":1590830885731,"user_tz":240,"elapsed":2478,"user":{"displayName":"Alejandro Martinez","photoUrl":"","userId":"09355511104721895281"}},"colab":{"base_uri":"https://localhost:8080/","height":249}},"source":["from keras.layers.convolutional import Conv2D\n","\n","#for each model freeze shallow half of conv layers\n","for model in model_list:\n","\n","    #get model name\n","    model_config = model.get_config()\n","    name = model_config['name']\n","    print(name)\n","\n","    #freeze shallower half of all convolutional layers\n","    conv_layers = []\n","    for layer in model.layers:\n","        if isinstance(layer,Conv2D):\n","          layer.trainable = True\n","          conv_layers.append(layer)\n","\n","    n_freeze = len(conv_layers)//2\n","    for layer in conv_layers[:n_freeze]:\n","       layer.trainable = False \n","\n","    for layer in model.layers:\n","        # layer.trainable = True\n","        print(layer,layer.trainable,layer.output_shape)\n","        \n","    \n","\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-1a495d214f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_list' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"LY1fdYNew1Xa","colab_type":"text"},"source":["<h2>Add randomly initialized FC layers to Source Model</h2>"]},{"cell_type":"code","metadata":{"id":"VSvPSfzcw1Xb","colab_type":"code","outputId":"ca1b6594-e064-4511-8305-c702f4caf435","executionInfo":{"status":"ok","timestamp":1590399043180,"user_tz":240,"elapsed":63909,"user":{"displayName":"Alejandro Martinez","photoUrl":"","userId":"09355511104721895281"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n","tuned_models = []\n","for model in model_list:\n","    \n","    #get model name\n","    model_config = model.get_config()\n","    name = model_config['name']\n","    \n","    #create transition model and add source model\n","    tuned_model = models.Sequential()\n","    tuned_model.add(model)\n","\n","\n","    #random initialization fixed for reproducibility\n","    np.random.seed(1000)\n","    \n","\n","    #add output layers for soft labels\n","    if \"resnet\" in name:\n","    #---------------RESNET LAYERS---------------\n","      tuned_model.add(AveragePooling2D())\n","      tuned_model.add(layers.Flatten())\n","      tuned_model.add(layers.Dense(1000, activation='relu'))\n","      tuned_model.add(layers.Dense(16, activation='softmax'))\n","\n","    elif \"densenet\" in name:\n","    #---------------DENSENET LAYERS---------------\n","      tuned_model.add(GlobalAveragePooling2D())\n","      tuned_model.add(layers.Dense(1000, activation='relu'))\n","      tuned_model.add(layers.Dense(16, activation='softmax'))\n","\n","    ####uncomment to add output layers for hard labels####\n","    # if \"resnet\" in name:\n","    # #---------------RESNET LAYERS---------------\n","    #   tuned_model.add(AveragePooling2D())\n","    #   tuned_model.add(layers.Flatten())\n","    #   tuned_model.add(layers.Dense(1000, activation='relu'))\n","    #   tuned_model.add(layers.Dense(1, activation='sigmoid'))\n","\n","    # elif \"densenet\" in name:\n","    # #---------------DENSENET LAYERS---------------\n","    #   tuned_model.add(GlobalAveragePooling2D())\n","    #   tuned_model.add(layers.Dense(1000, activation='relu'))\n","    #   tuned_model.add(layers.Dense(1, activation='sigmoid'))\n","\n","\n","    #add model to model list\n","    tuned_models.append(tuned_model)\n","\n","#display each model summary\n","[print(model.summary()) for model in tuned_models]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","densenet121 (Model)          (None, 7, 7, 1024)        7037504   \n","_________________________________________________________________\n","global_average_pooling2d_3 ( (None, 1024)              0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1000)              1025000   \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 16)                16016     \n","=================================================================\n","Total params: 8,078,520\n","Trainable params: 5,626,168\n","Non-trainable params: 2,452,352\n","_________________________________________________________________\n","None\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","densenet169 (Model)          (None, 7, 7, 1664)        12642880  \n","_________________________________________________________________\n","global_average_pooling2d_4 ( (None, 1664)              0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1000)              1665000   \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 16)                16016     \n","=================================================================\n","Total params: 14,323,896\n","Trainable params: 10,150,200\n","Non-trainable params: 4,173,696\n","_________________________________________________________________\n","None\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50v2 (Model)           (None, 7, 7, 2048)        23564800  \n","_________________________________________________________________\n","average_pooling2d_1 (Average (None, 3, 3, 2048)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1000)              18433000  \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 16)                16016     \n","=================================================================\n","Total params: 42,013,816\n","Trainable params: 39,809,016\n","Non-trainable params: 2,204,800\n","_________________________________________________________________\n","None\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet101v2 (Model)          (None, 7, 7, 2048)        42626560  \n","_________________________________________________________________\n","average_pooling2d_2 (Average (None, 3, 3, 2048)        0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 1000)              18433000  \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 16)                16016     \n","=================================================================\n","Total params: 61,075,576\n","Trainable params: 49,108,984\n","Non-trainable params: 11,966,592\n","_________________________________________________________________\n","None\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[None, None, None, None]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"70Ah_81dw1Xh","colab_type":"text"},"source":["<h2>Learn the Transition task</h2>"]},{"cell_type":"code","metadata":{"id":"wGseRrrhw1Xl","colab_type":"code","outputId":"e3e9a82a-8956-4843-d92b-87b29032fc4c","executionInfo":{"status":"ok","timestamp":1590404552846,"user_tz":240,"elapsed":4133819,"user":{"displayName":"Alejandro Martinez","photoUrl":"","userId":"09355511104721895281"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.optimizers import SGD, Adam, Adadelta\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","from keras.metrics import AUC\n","from keras.backend import manual_variable_initialization\n"," \n","\n","#start counter\n","start = time.perf_counter()\n","\n","#optimizer\n","if (\"resnet\" in model.layers[0].name or \"densenet\"in model.layers[0].name):\n","  opt = SGD() \n","else:\n","  opt = Adadelta()\n","\n","\n","for model in tuned_models[1:]:\n","\n","  #create save path\n","  name = model.layers[0].name +\"_soft_labels_15epochs.hdf5\"\n","  path = os.path.join(model_dir,name)\n"," \n","  #compile model\n","  model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","\n","\n","  #train model and save model with highest validation accuracy\n","  callbacks = [ModelCheckpoint(filepath=path, verbose=1, save_best_only=True, monitor='val_accuracy',mode='max')]\n","  model.fit(X_train,y_train,verbose=1,use_multiprocessing=True,epochs=15,validation_data=(X_test,y_test),callbacks=callbacks,shuffle=True)\n","\n","\n","finish = time.perf_counter()\n","print(f'this process took {finish-start} seconds')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","densenet169 (Model)          (None, 7, 7, 1664)        12642880  \n","_________________________________________________________________\n","global_average_pooling2d_4 ( (None, 1664)              0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1000)              1665000   \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 16)                16016     \n","=================================================================\n","Total params: 14,323,896\n","Trainable params: 10,150,200\n","Non-trainable params: 4,173,696\n","_________________________________________________________________\n","None\n","compiled\n","Train on 8140 samples, validate on 2036 samples\n","Epoch 1/15\n","8140/8140 [==============================] - 208s 26ms/step - loss: 1.2056 - accuracy: 0.6243 - val_loss: 2.5714 - val_accuracy: 0.4136\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.41356, saving model to tuned_models/densenet169_soft_labels_15epochs.hdf5\n","Epoch 2/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.7401 - accuracy: 0.7561 - val_loss: 1.9426 - val_accuracy: 0.5417\n","\n","Epoch 00002: val_accuracy improved from 0.41356 to 0.54175, saving model to tuned_models/densenet169_soft_labels_15epochs.hdf5\n","Epoch 3/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.5946 - accuracy: 0.8045 - val_loss: 0.8880 - val_accuracy: 0.7382\n","\n","Epoch 00003: val_accuracy improved from 0.54175 to 0.73821, saving model to tuned_models/densenet169_soft_labels_15epochs.hdf5\n","Epoch 4/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.4926 - accuracy: 0.8318 - val_loss: 1.6679 - val_accuracy: 0.6208\n","\n","Epoch 00004: val_accuracy did not improve from 0.73821\n","Epoch 5/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.4100 - accuracy: 0.8645 - val_loss: 1.1921 - val_accuracy: 0.7215\n","\n","Epoch 00005: val_accuracy did not improve from 0.73821\n","Epoch 6/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.3482 - accuracy: 0.8796 - val_loss: 1.2019 - val_accuracy: 0.7102\n","\n","Epoch 00006: val_accuracy did not improve from 0.73821\n","Epoch 7/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.2914 - accuracy: 0.9033 - val_loss: 1.0647 - val_accuracy: 0.7603\n","\n","Epoch 00007: val_accuracy improved from 0.73821 to 0.76031, saving model to tuned_models/densenet169_soft_labels_15epochs.hdf5\n","Epoch 8/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.2474 - accuracy: 0.9149 - val_loss: 1.5811 - val_accuracy: 0.6930\n","\n","Epoch 00008: val_accuracy did not improve from 0.76031\n","Epoch 9/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.1986 - accuracy: 0.9333 - val_loss: 1.3043 - val_accuracy: 0.7441\n","\n","Epoch 00009: val_accuracy did not improve from 0.76031\n","Epoch 10/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.1829 - accuracy: 0.9414 - val_loss: 1.1412 - val_accuracy: 0.7608\n","\n","Epoch 00010: val_accuracy improved from 0.76031 to 0.76081, saving model to tuned_models/densenet169_soft_labels_15epochs.hdf5\n","Epoch 11/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.1621 - accuracy: 0.9475 - val_loss: 1.4816 - val_accuracy: 0.7392\n","\n","Epoch 00011: val_accuracy did not improve from 0.76081\n","Epoch 12/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.1464 - accuracy: 0.9518 - val_loss: 1.8047 - val_accuracy: 0.7092\n","\n","Epoch 00012: val_accuracy did not improve from 0.76081\n","Epoch 13/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.1295 - accuracy: 0.9563 - val_loss: 1.5837 - val_accuracy: 0.7426\n","\n","Epoch 00013: val_accuracy did not improve from 0.76081\n","Epoch 14/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.1132 - accuracy: 0.9646 - val_loss: 1.8406 - val_accuracy: 0.7407\n","\n","Epoch 00014: val_accuracy did not improve from 0.76081\n","Epoch 15/15\n","8140/8140 [==============================] - 146s 18ms/step - loss: 0.1060 - accuracy: 0.9673 - val_loss: 1.4299 - val_accuracy: 0.7814\n","\n","Epoch 00015: val_accuracy improved from 0.76081 to 0.78143, saving model to tuned_models/densenet169_soft_labels_15epochs.hdf5\n","fit\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50v2 (Model)           (None, 7, 7, 2048)        23564800  \n","_________________________________________________________________\n","average_pooling2d_1 (Average (None, 3, 3, 2048)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1000)              18433000  \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 16)                16016     \n","=================================================================\n","Total params: 42,013,816\n","Trainable params: 39,809,016\n","Non-trainable params: 2,204,800\n","_________________________________________________________________\n","None\n","compiled\n","Train on 8140 samples, validate on 2036 samples\n","Epoch 1/15\n","8140/8140 [==============================] - 87s 11ms/step - loss: 1.3889 - accuracy: 0.5872 - val_loss: 2.0295 - val_accuracy: 0.5363\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.53635, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","Epoch 2/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.7844 - accuracy: 0.7440 - val_loss: 1.2939 - val_accuracy: 0.6675\n","\n","Epoch 00002: val_accuracy improved from 0.53635 to 0.66749, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","Epoch 3/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.6090 - accuracy: 0.7931 - val_loss: 1.0053 - val_accuracy: 0.6994\n","\n","Epoch 00003: val_accuracy improved from 0.66749 to 0.69941, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","Epoch 4/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.5070 - accuracy: 0.8249 - val_loss: 0.8311 - val_accuracy: 0.7692\n","\n","Epoch 00004: val_accuracy improved from 0.69941 to 0.76916, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","Epoch 5/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.4063 - accuracy: 0.8568 - val_loss: 0.8026 - val_accuracy: 0.7937\n","\n","Epoch 00005: val_accuracy improved from 0.76916 to 0.79371, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","Epoch 6/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.3265 - accuracy: 0.8816 - val_loss: 0.9011 - val_accuracy: 0.7957\n","\n","Epoch 00006: val_accuracy improved from 0.79371 to 0.79568, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","Epoch 7/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.2635 - accuracy: 0.9068 - val_loss: 1.1583 - val_accuracy: 0.7736\n","\n","Epoch 00007: val_accuracy did not improve from 0.79568\n","Epoch 8/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.2002 - accuracy: 0.9307 - val_loss: 0.9522 - val_accuracy: 0.8021\n","\n","Epoch 00008: val_accuracy improved from 0.79568 to 0.80206, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","Epoch 9/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.1600 - accuracy: 0.9490 - val_loss: 0.9882 - val_accuracy: 0.8065\n","\n","Epoch 00009: val_accuracy improved from 0.80206 to 0.80648, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","Epoch 10/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.1245 - accuracy: 0.9601 - val_loss: 1.3669 - val_accuracy: 0.7844\n","\n","Epoch 00010: val_accuracy did not improve from 0.80648\n","Epoch 11/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.0993 - accuracy: 0.9704 - val_loss: 1.2754 - val_accuracy: 0.7913\n","\n","Epoch 00011: val_accuracy did not improve from 0.80648\n","Epoch 12/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.0725 - accuracy: 0.9776 - val_loss: 1.2888 - val_accuracy: 0.8075\n","\n","Epoch 00012: val_accuracy improved from 0.80648 to 0.80747, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","Epoch 13/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.0742 - accuracy: 0.9799 - val_loss: 1.2764 - val_accuracy: 0.8075\n","\n","Epoch 00013: val_accuracy did not improve from 0.80747\n","Epoch 14/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.0545 - accuracy: 0.9871 - val_loss: 1.2253 - val_accuracy: 0.8050\n","\n","Epoch 00014: val_accuracy did not improve from 0.80747\n","Epoch 15/15\n","8140/8140 [==============================] - 74s 9ms/step - loss: 0.0422 - accuracy: 0.9892 - val_loss: 1.3914 - val_accuracy: 0.8139\n","\n","Epoch 00015: val_accuracy improved from 0.80747 to 0.81385, saving model to tuned_models/resnet50v2_soft_labels_15epochs.hdf5\n","fit\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet101v2 (Model)          (None, 7, 7, 2048)        42626560  \n","_________________________________________________________________\n","average_pooling2d_2 (Average (None, 3, 3, 2048)        0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 1000)              18433000  \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 16)                16016     \n","=================================================================\n","Total params: 61,075,576\n","Trainable params: 49,108,984\n","Non-trainable params: 11,966,592\n","_________________________________________________________________\n","None\n","compiled\n","Train on 8140 samples, validate on 2036 samples\n","Epoch 1/15\n","8140/8140 [==============================] - 156s 19ms/step - loss: 1.3739 - accuracy: 0.5865 - val_loss: 2.0754 - val_accuracy: 0.4661\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.46611, saving model to tuned_models/resnet101v2_soft_labels_15epochs.hdf5\n","Epoch 2/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.7776 - accuracy: 0.7498 - val_loss: 1.1695 - val_accuracy: 0.7117\n","\n","Epoch 00002: val_accuracy improved from 0.46611 to 0.71169, saving model to tuned_models/resnet101v2_soft_labels_15epochs.hdf5\n","Epoch 3/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.5852 - accuracy: 0.8069 - val_loss: 0.8189 - val_accuracy: 0.7721\n","\n","Epoch 00003: val_accuracy improved from 0.71169 to 0.77210, saving model to tuned_models/resnet101v2_soft_labels_15epochs.hdf5\n","Epoch 4/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.4512 - accuracy: 0.8491 - val_loss: 0.8230 - val_accuracy: 0.7750\n","\n","Epoch 00004: val_accuracy improved from 0.77210 to 0.77505, saving model to tuned_models/resnet101v2_soft_labels_15epochs.hdf5\n","Epoch 5/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.3363 - accuracy: 0.8821 - val_loss: 1.0057 - val_accuracy: 0.7814\n","\n","Epoch 00005: val_accuracy improved from 0.77505 to 0.78143, saving model to tuned_models/resnet101v2_soft_labels_15epochs.hdf5\n","Epoch 6/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.2603 - accuracy: 0.9139 - val_loss: 0.9769 - val_accuracy: 0.7780\n","\n","Epoch 00006: val_accuracy did not improve from 0.78143\n","Epoch 7/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.1880 - accuracy: 0.9386 - val_loss: 1.0294 - val_accuracy: 0.8045\n","\n","Epoch 00007: val_accuracy improved from 0.78143 to 0.80452, saving model to tuned_models/resnet101v2_soft_labels_15epochs.hdf5\n","Epoch 8/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.1324 - accuracy: 0.9613 - val_loss: 1.0668 - val_accuracy: 0.8006\n","\n","Epoch 00008: val_accuracy did not improve from 0.80452\n","Epoch 9/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.0866 - accuracy: 0.9765 - val_loss: 1.1538 - val_accuracy: 0.8084\n","\n","Epoch 00009: val_accuracy improved from 0.80452 to 0.80845, saving model to tuned_models/resnet101v2_soft_labels_15epochs.hdf5\n","Epoch 10/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.0653 - accuracy: 0.9835 - val_loss: 1.3081 - val_accuracy: 0.7991\n","\n","Epoch 00010: val_accuracy did not improve from 0.80845\n","Epoch 11/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.0505 - accuracy: 0.9883 - val_loss: 1.3477 - val_accuracy: 0.8065\n","\n","Epoch 00011: val_accuracy did not improve from 0.80845\n","Epoch 12/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.0477 - accuracy: 0.9881 - val_loss: 1.3345 - val_accuracy: 0.8001\n","\n","Epoch 00012: val_accuracy did not improve from 0.80845\n","Epoch 13/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.0411 - accuracy: 0.9914 - val_loss: 1.2834 - val_accuracy: 0.8001\n","\n","Epoch 00013: val_accuracy did not improve from 0.80845\n","Epoch 14/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.0399 - accuracy: 0.9893 - val_loss: 1.3802 - val_accuracy: 0.7991\n","\n","Epoch 00014: val_accuracy did not improve from 0.80845\n","Epoch 15/15\n","8140/8140 [==============================] - 125s 15ms/step - loss: 0.0279 - accuracy: 0.9932 - val_loss: 1.4189 - val_accuracy: 0.8070\n","\n","Epoch 00015: val_accuracy did not improve from 0.80845\n","fit\n","this process took 5509.244747981 seconds\n"],"name":"stdout"}]}]}